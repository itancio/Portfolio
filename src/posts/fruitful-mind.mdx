---
title: 'Fruitful Mind'
abstract: 'A UX design solution addressing the mental health challenges faced by children from Asian immigrant families, 
    promoting a safe digital space for self-expression and support.'
keywords: ['figma', 'ux design', 'user-centric']
categories: ['Design']
date: '2023-05-03'
banner: /static/fruitfulMind/orange1.png
source_code: https://www.figma.com/file/eQYfEQiJai68B68lXl8ClT/Mental-Health-(w%2FJason)?type=design&node-id=10-163&mode=design&t=5ndBeVklVCTHwyOR-0
---

### Problem Statement
Children from Asian immigrant families often face additional challenges 
when trying to access mental health services. One of the most significant difficulties 
that they have to face is the stigma attached to mental health within many Asian communities. 
They may feel ashamed or embarrassed to talk about their mental health struggles 
and may even be encouraged to hide them from others. Many also struggle with the pressures 
of living up to their families' expectations and balancing their cultural identity. 
All of these factors can make it even harder for Asian immigrant kids to find the counseling services they need.

### Focused Question
1. How can we facilitate a safe-space public discussion? 
2. How can we inform/educate users that certain words (bullying, derogatory, racist, insensitive, 
inappropriate, comments, etc) impact the way others are feeling or even exacerbate their underlying issues 
that they are already causing their anxiety, depression or other stressors

### Solution
Our goal was to create culturally sensitive and appropriate resources to help individuals 
overcome the barriers and seek the support they need to address their mental health needs. 

To be more specific, our app will include two main features:

1. Discussion Board: a place for users to share what is in their mind and get responses from other users. 

- Behavioral training module will be enforced if inappropriate content is detected
- Blurry filter will be added if a post is identified as harmful or inappropriate 

2. Personalized Coping Task and Journaling: besides the discussion board, 
users will have a variety of tasks to complete and help them destress. 
Users can cope with their anxiety through daily tasks like  journaling, arts and exercises.

### Design Considerations
1. Empathy and User-Centered Design:
At the heart of UX design is a deep understanding and empathy for the user. 
The design prioritizes on the needs, wants, and limitations of the users. 
During our daily check-in, users will engage with an AI chatbot designed to
initiate conversations about their feelings and thoughts, 
mirroring an interaction with a caring friend inquiring 
about their well-being. This approach emphasizes 
recognizing and addressing the emotional needs of the user, 
ensuring that the interface or 
interaction feels personal and relevant. By prioritizing the user's emotional journey and well-being, 
the design promotes a positive, meaningful, and impactful user experience.

![Thumbnail](/static/fruitfulMind/fruitfulMind-landingpage.png)

2. Survey with Progress Bar: 
Based on the principle of Visibility of system status, we include a progress bar 
at the bottom of the screen to inform the user how much more screens 
they have to go through to complete the survey. It prevents the users from quitting the survey halfway 
by giving them a certain level of expectation. This page is created to respond 
to one of the user’s pain points which the user hope 
that someone checks in once in a while how they are doing. This check-in page set 
that user to a journey of personal reflection right from the start of using the app.  

![Thumbnail](/static/fruitfulMind/fruitfulMind-activity.png)

3. Daily Task Streak: 
Based on the idea of loss aversion, we implemented a streak system to encourage 
users to complete their task daily. Users will lose their streak if they don’t complete task each day. 

![Thumbnail](/static/fruitfulMind/fruitfulMind-journal.png)

4. Layered Protection through Progressive Disclosure: 
Progressive disclosure is a strategy that involves providing only the information 
or features necessary at any given time, revealing more as the user requires or requests it. 
- Blurring explicit content serves as an immediate visual barrier, 
preventing inadvertent exposure to potentially sensitive material. 
This initial layer gives users the choice to engage further or avoid the content entirely.
- Content bubbles act as a secondary layer, succinctly informing users about the nature 
or theme of the discussion. It prepares users for what to expect, allowing them 
to make informed decisions about engagement.
- The filtering system represents a more proactive approach, 
where you're preemptively categorizing and, in certain instances, 
removing content that breaches the platform's guidelines. 
This ensures that users aren't exposed to content they haven’t actively chosen to see.

Together, these elements champion user autonomy, comfort, and safety, 
ensuring users have both awareness and control over the content they encounter.

![Thumbnail](/static/fruitfulMind/fruitfulMind-discussion.png)

5. We're committed to fostering a secure and inclusive environment on our public discussion boards, 
balancing user freedom with safety. One challenge we face is ensuring this without excessive censorship 
or surveillance.

To address potential misuse, we've devised a feature specifically for individuals 
who might unintentionally or persistently breach our community guidelines. 
It's crucial that users aren't banned without understanding their missteps or being given 
an opportunity to make amends.

To this end, we've introduced a "Safe-Space Education" module. This is designed to:
- Clarify the specific reason for their violation.
- Educate them on the repercussions of their words or actions.
- Offer a chance to amend their behavior, possibly by rephrasing their comments or opting 
to share reflections in a private journal space.

Through this approach, we aim to promote understanding and positive change, 
rather than simply penalizing users.

![Thumbnail](/static/fruitfulMind/fruitfulMind-training.png)

### Potential Areas of Improvements
We are using an AI/ algorigthm to trigger these module. 
It's important to recognize that while AI and algorithms are powerful tools, 
they are not infallible, especially when deciphering nuanced human behavior and language.

Here are some potential areas of improvement and considerations:

1. **Context Sensitivity**: Algorithms often struggle to interpret the context in which words or phrases are used. 
A term that's benign in one context might be offensive in another. An enhancement could be training the algorithm on more diverse datasets that encapsulate a broader range of contexts and nuances.

2. **Feedback Loop**: Incorporate a user feedback mechanism. When a post is flagged or blurred, 
allow users to confirm or contest the decision. This feedback can be used to continually refine and train the algorithm.

3. **Defined Violent Behaviors**:
   - **Explicit threats**: Any direct threats of harm or violence towards individuals or groups.
   - **Graphic descriptions**: Vivid depictions of violent acts, whether real or fictional.
   - **Promotion of harm**: Encouraging others to engage in harmful or dangerous activities.
   - **Demeaning language**: Use of slurs, derogatory terms, or other language meant to belittle or oppress.
   - **Disturbing content**: Sharing or promoting content that showcases real-life harm, pain, or violence without proper context or warning.
   - **Cyberbullying**: Any form of online harassment or intimidation.

4. **User Intent Analysis**: It's challenging for an algorithm to gauge user intent. 
Collaborating with experts in linguistics or behavioral psychology might provide deeper insights into how language 
can be used to infer underlying intentions.

5. **Collaborative Filtering**: Instead of just analyzing content in isolation, look at the patterns of user interaction. 
Users who frequently engage in controversial or borderline discussions might need more scrutiny than others.

6. **Transparency**: Clearly communicate to users how the algorithm operates and the criteria it uses to flag content. 
This transparency can build trust and also reduce potential misunderstandings.

7. **Human Oversight**: Consider a hybrid approach where crucial decisions are reviewed by a human moderator, 
especially in ambiguous cases. Human judgment can complement the algorithm's decisions and bridge its limitations.

8. **Regular Updates**: Language and societal norms evolve. Regularly update the algorithm to account for new slang, idioms, 
and cultural contexts.

Implementing these improvements and considerations can help strike a balance between maintaining user safety and 
ensuring freedom of expression.

